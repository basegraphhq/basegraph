{
  "version": "1.0",
  "issue_context": "Token Consumption - Track token spent per issue",
  "fixtures": [
    {
      "id": "token-tracking-in-agents",
      "intent": "Understanding how tokens are currently tracked in planner and explore agents",
      "keywords": ["token", "tracking", "planner", "explore", "prompt_tokens", "completion_tokens", "accumulation", "usage"],
      "scope": ["brain/planner.go", "brain/explore_agent.go"],
      "report": "## Answer\nToken usage (prompt/completion) is accumulated in both Planner and ExploreAgent during their execution loops, but only logged - not persisted to database.\n\n## Evidence\n- brain/planner.go:113-125 — Planner accumulates `totalPromptTokens += resp.PromptTokens` and `totalCompletionTokens += resp.CompletionTokens` per iteration\n- brain/explore_agent.go:126-138 — ExploreAgent does the same accumulation pattern\n- brain/explore_agent.go:178-189 — Synthesis call also adds to totals\n\n## Snippets\n```go\n// planner.go:113-125\ntotalPromptTokens += resp.PromptTokens\ntotalCompletionTokens += resp.CompletionTokens\nslog.DebugContext(ctx, \"planner iteration completed\", \"prompt_tokens\", resp.PromptTokens)\n```\n\n## Confidence\nhigh — Direct code inspection confirms the pattern\n\n---\n\n**Confidence Assessment:** high — The token tracking logic is explicit and consistent across both agents."
    },
    {
      "id": "llm-eval-persistence",
      "intent": "Understanding LLMEval model and how it could persist token usage",
      "keywords": ["LLMEval", "persistence", "database", "store", "issue_id", "prompt_tokens", "completion_tokens", "save", "persist"],
      "scope": ["model/llm_eval.go", "store/llm_eval.go", "store/interfaces.go"],
      "report": "## Answer\nThere is an existing `LLMEval` model with `IssueID`, `PromptTokens`, and `CompletionTokens` fields, plus a store with `Create` and `ListByIssue` methods. However, no code currently calls the store to persist token usage.\n\n## Evidence\n- model/llm_eval.go:14-31 — `LLMEval` struct has `IssueID *int64`, `PromptTokens *int`, `CompletionTokens *int`\n- store/llm_eval.go:20-48 — `InsertLLMEval` persists these fields\n- store/interfaces.go:144-152 — `LLMEvalStore` interface supports `Create`, `ListByIssue`, `GetStats`\n\n## Snippets\n```go\n// model/llm_eval.go\ntype LLMEval struct {\n    ID               int64   `json:\"id\"`\n    IssueID          *int64  `json:\"issue_id,omitempty\"`\n    Stage            string  `json:\"stage\"`\n    PromptTokens     *int    `json:\"prompt_tokens,omitempty\"`\n    CompletionTokens *int    `json:\"completion_tokens,omitempty\"`\n}\n```\n\n## Confidence\nhigh — Model and store exist but are unused\n\n---\n\n**Confidence Assessment:** high — The infrastructure exists, just needs to be wired up."
    },
    {
      "id": "issue-model-structure",
      "intent": "Understanding Issue model and what fields it has",
      "keywords": ["Issue", "model", "struct", "fields", "CodeFindings", "Keywords", "Discussions", "schema"],
      "scope": ["model/issue.go", "store/issue.go"],
      "report": "## Answer\nThe `Issue` model stores issue metadata, discussions, keywords, code findings, and processing state. It does NOT currently have token usage fields.\n\n## Evidence\n- model/issue.go:83-109 — Issue struct with ID, IntegrationID, Title, Description, Labels, Keywords, CodeFindings, Discussions, Spec, ProcessingStatus\n- store/issue.go:21-61 — UpsertIssueParams marshals Keywords/CodeFindings/Learnings/Discussions as JSON\n\n## Snippets\n```go\n// model/issue.go:83-109\ntype Issue struct {\n    ID                int64         `json:\"id\"`\n    IntegrationID     int64         `json:\"integration_id\"`\n    Keywords          []Keyword     `json:\"keywords,omitempty\"`\n    CodeFindings      []CodeFinding `json:\"code_findings,omitempty\"`\n    Discussions       []Discussion  `json:\"discussions,omitempty\"`\n    ProcessingStatus  ProcessingStatus `json:\"processing_status\"`\n}\n```\n\n## Confidence\nhigh — Comprehensive view of Issue model\n\n---\n\n**Confidence Assessment:** high — Direct struct inspection."
    },
    {
      "id": "orchestrator-engagement-flow",
      "intent": "Understanding how orchestrator processes issues and where token tracking could be added",
      "keywords": ["orchestrator", "HandleEngagement", "IssueID", "EventLogID", "planner", "context", "flow", "processing"],
      "scope": ["brain/orchestrator.go"],
      "report": "## Answer\nOrchestrator's `HandleEngagement` loads an issue, runs the planner, and executes actions. IssueID is available in context throughout. This is the ideal place to persist aggregated token counts after planning completes.\n\n## Evidence\n- brain/orchestrator.go:19-24 — `EngagementInput` has `IssueID int64`, `EventLogID int64`\n- brain/orchestrator.go:94-100 — Context enriched with IssueID via `logger.WithLogFields`\n- brain/orchestrator.go:134-136 — `output, err := o.planner.Plan(ctx, messages)` is where planning happens\n- brain/orchestrator.go:94-165 — After planning, actions are executed, then function returns (end-of-processing hook point)\n\n## Snippets\n```go\n// brain/orchestrator.go:94-100\nctx = logger.WithLogFields(ctx, logger.LogFields{\n    IssueID:    &input.IssueID,\n    EventLogID: &input.EventLogID,\n})\n```\n\n## Confidence\nhigh — Clear insertion point identified\n\n---\n\n**Confidence Assessment:** high — The orchestrator flow is well-defined and IssueID is available."
    },
    {
      "id": "http-api-routes",
      "intent": "Understanding what HTTP API routes exist and whether there's an issue endpoint",
      "keywords": ["HTTP", "API", "routes", "router", "issue", "endpoint", "v1", "REST"],
      "scope": ["http/router/router.go", "http/dto"],
      "report": "## Answer\nThe HTTP API currently has `/api/v1/users`, `/api/v1/organizations`, and `/api/v1/integrations/gitlab` routes. There is NO `/api/v1/issues` endpoint yet.\n\n## Evidence\n- http/router/router.go:25-35 — Only registers users/orgs/gitlab routes under `/api/v1`\n- http/dto/*.go — DTO patterns exist for user/org but no IssueResponse DTO\n- http/middleware/auth.go:22-24 — TODO comment mentions auth middleware not applied to v1 routes yet\n\n## Snippets\n```go\n// http/router/router.go:17-35\nv1 := router.Group(\"/api/v1\") {\n    // users, organizations, gitlab...\n    // NO issues route\n}\n```\n\n## Confidence\nhigh — No issue API exists\n\n---\n\n**Confidence Assessment:** high — Exhaustive search of router confirms no issue endpoints."
    },
    {
      "id": "event-log-pipeline",
      "intent": "Understanding how events flow through the system tied to issues",
      "keywords": ["EventLog", "event", "pipeline", "queue", "IssueID", "Redis", "ingest", "async"],
      "scope": ["model/event_log.go", "service/event_ingest.go"],
      "report": "## Answer\nEvents are ingested via `EventIngestService`, creating `EventLog` records with `IssueID`, then enqueued to Redis for async processing. This pattern could be extended for token tracking.\n\n## Evidence\n- model/event_log.go:8-21 — EventLog has WorkspaceID, IssueID, EventType, Payload, processing fields\n- service/event_ingest.go:212-255 — CreateOrGet EventLog then enqueue to Redis with IssueID/EventLogID\n\n## Snippets\n```go\n// model/event_log.go\ntype EventLog struct {\n    ID          int64\n    WorkspaceID int64\n    IssueID     *int64\n    EventType   string\n    Payload     json.RawMessage\n}\n```\n\n## Confidence\nmedium — Pattern exists but may not directly apply to token tracking\n\n---\n\n**Confidence Assessment:** medium — The event pipeline is issue-centric but token tracking might need a simpler approach."
    }
  ]
}
